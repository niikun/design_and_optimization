{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: x = [1.6 2.4], Loss = 13.0\n",
      "Iteration 2: x = [1.28      1.9200001], Loss = 8.320000648498535\n",
      "Iteration 3: x = [1.0239999 1.536    ], Loss = 5.32480001449585\n",
      "Iteration 4: x = [0.8191999 1.2288   ], Loss = 3.407871961593628\n",
      "Iteration 5: x = [0.6553599  0.98304003], Loss = 2.1810381412506104\n",
      "Iteration 6: x = [0.52428794 0.786432  ], Loss = 1.3958643674850464\n",
      "Iteration 7: x = [0.41943035 0.6291456 ], Loss = 0.8933531641960144\n",
      "Iteration 8: x = [0.3355443 0.5033165], Loss = 0.5717460513114929\n",
      "Iteration 9: x = [0.26843542 0.40265322], Loss = 0.36591750383377075\n",
      "Iteration 10: x = [0.21474834 0.32212257], Loss = 0.23418718576431274\n",
      "Iteration 11: x = [0.17179868 0.25769806], Loss = 0.1498797982931137\n",
      "Iteration 12: x = [0.13743894 0.20615844], Loss = 0.09592308104038239\n",
      "Iteration 13: x = [0.10995115 0.16492675], Loss = 0.06139076501131058\n",
      "Iteration 14: x = [0.08796092 0.13194141], Loss = 0.039290089160203934\n",
      "Iteration 15: x = [0.07036874 0.10555313], Loss = 0.02514565922319889\n",
      "Iteration 16: x = [0.05629499 0.0844425 ], Loss = 0.016093222424387932\n",
      "Iteration 17: x = [0.04503599 0.067554  ], Loss = 0.010299662128090858\n",
      "Iteration 18: x = [0.03602879 0.0540432 ], Loss = 0.006591783836483955\n",
      "Iteration 19: x = [0.02882304 0.04323456], Loss = 0.004218741785734892\n",
      "Iteration 20: x = [0.02305843 0.03458765], Loss = 0.0026999949477612972\n",
      "Iteration 21: x = [0.01844674 0.02767012], Loss = 0.0017279968596994877\n",
      "Iteration 22: x = [0.01475739 0.0221361 ], Loss = 0.001105917850509286\n",
      "Iteration 23: x = [0.01180592 0.01770888], Loss = 0.000707787461578846\n",
      "Iteration 24: x = [0.00944473 0.0141671 ], Loss = 0.00045298400800675154\n",
      "Iteration 25: x = [0.00755579 0.01133368], Loss = 0.00028990977443754673\n",
      "Iteration 26: x = [0.00604463 0.00906694], Loss = 0.00018554225971456617\n",
      "Iteration 27: x = [0.0048357  0.00725356], Loss = 0.00011874703341163695\n",
      "Iteration 28: x = [0.00386856 0.00580284], Loss = 7.59981048759073e-05\n",
      "Iteration 29: x = [0.00309485 0.00464228], Loss = 4.863877984462306e-05\n",
      "Iteration 30: x = [0.00247588 0.00371382], Loss = 3.112882041023113e-05\n",
      "Iteration 31: x = [0.0019807  0.00297106], Loss = 1.9922445062547922e-05\n",
      "Iteration 32: x = [0.00158456 0.00237685], Loss = 1.275036447623279e-05\n",
      "Iteration 33: x = [0.00126765 0.00190148], Loss = 8.160232937370893e-06\n",
      "Iteration 34: x = [0.00101412 0.00152118], Loss = 5.222549134487053e-06\n",
      "Iteration 35: x = [0.0008113  0.00121694], Loss = 3.342431455166661e-06\n",
      "Iteration 36: x = [0.00064904 0.00097356], Loss = 2.139156094926875e-06\n",
      "Iteration 37: x = [0.00051923 0.00077884], Loss = 1.369059873468359e-06\n",
      "Iteration 38: x = [0.00041538 0.00062308], Loss = 8.761983281146968e-07\n",
      "Iteration 39: x = [0.00033231 0.00049846], Loss = 5.607669208984589e-07\n",
      "Iteration 40: x = [0.00026585 0.00039877], Loss = 3.588908157325932e-07\n",
      "Iteration 41: x = [0.00021268 0.00031901], Loss = 2.2969013002693828e-07\n",
      "Iteration 42: x = [0.00017014 0.00025521], Loss = 1.4700168549097725e-07\n",
      "Iteration 43: x = [0.00013611 0.00020417], Loss = 9.408107359831774e-08\n",
      "Iteration 44: x = [0.00010889 0.00016334], Loss = 6.021188880822592e-08\n",
      "Iteration 45: x = [8.7112290e-05 1.3066843e-04], Loss = 3.853561025835006e-08\n",
      "Iteration 46: x = [6.96898351e-05 1.04534745e-04], Loss = 2.4662789144258568e-08\n",
      "Iteration 47: x = [5.575187e-05 8.362780e-05], Loss = 1.578418640235668e-08\n",
      "Iteration 48: x = [4.4601496e-05 6.6902241e-05], Loss = 1.0101879333035413e-08\n",
      "Iteration 49: x = [3.5681198e-05 5.3521791e-05], Loss = 6.4652034836854e-09\n",
      "Iteration 50: x = [2.8544959e-05 4.2817432e-05], Loss = 4.1377301585043824e-09\n",
      "Iteration 51: x = [2.2835968e-05 3.4253946e-05], Loss = 2.648147034989279e-09\n",
      "Iteration 52: x = [1.8268775e-05 2.7403157e-05], Loss = 1.6948142889106066e-09\n",
      "Iteration 53: x = [1.4615020e-05 2.1922526e-05], Loss = 1.0846811226983277e-09\n",
      "Iteration 54: x = [1.16920155e-05 1.75380210e-05], Loss = 6.941959229678218e-10\n",
      "Iteration 55: x = [9.3536128e-06 1.4030416e-05], Loss = 4.442854140140895e-10\n",
      "Iteration 56: x = [7.4828904e-06 1.1224333e-05], Loss = 2.843426605281252e-10\n",
      "Iteration 57: x = [5.9863123e-06 8.9794667e-06], Loss = 1.819792927459929e-10\n",
      "Iteration 58: x = [4.7890499e-06 7.1835734e-06], Loss = 1.1646675290855057e-10\n",
      "Iteration 59: x = [3.8312401e-06 5.7468587e-06], Loss = 7.453872241658388e-11\n",
      "Iteration 60: x = [3.0649921e-06 4.5974871e-06], Loss = 4.770478456705973e-11\n",
      "Iteration 61: x = [2.4519936e-06 3.6779898e-06], Loss = 3.0531063788252766e-11\n",
      "Iteration 62: x = [1.9615950e-06 2.9423918e-06], Loss = 1.9539881865315856e-11\n",
      "Iteration 63: x = [1.5692760e-06 2.3539135e-06], Loss = 1.2505524393802148e-11\n",
      "Iteration 64: x = [1.2554208e-06 1.8831308e-06], Loss = 8.003536201839356e-12\n",
      "Iteration 65: x = [1.0043366e-06 1.5065046e-06], Loss = 5.122263290607831e-12\n",
      "Iteration 66: x = [8.0346928e-07 1.2052037e-06], Loss = 3.2782483325166645e-12\n",
      "Iteration 67: x = [6.4277543e-07 9.6416295e-07], Loss = 2.0980788720953436e-12\n",
      "Iteration 68: x = [5.1422035e-07 7.7133035e-07], Loss = 1.3427705128354894e-12\n",
      "Iteration 69: x = [4.1137628e-07 6.1706430e-07], Loss = 8.593731195410959e-13\n",
      "Iteration 70: x = [3.2910103e-07 4.9365144e-07], Loss = 5.49998794337897e-13\n",
      "Iteration 71: x = [2.6328081e-07 3.9492116e-07], Loss = 3.5199924572348884e-13\n",
      "Iteration 72: x = [2.1062465e-07 3.1593692e-07], Loss = 2.25279511842022e-13\n",
      "Iteration 73: x = [1.6849972e-07 2.5274954e-07], Loss = 1.4417888541048973e-13\n",
      "Iteration 74: x = [1.3479978e-07 2.0219963e-07], Loss = 9.227448856006723e-14\n",
      "Iteration 75: x = [1.07839824e-07 1.61759701e-07], Loss = 5.905567240739248e-14\n",
      "Iteration 76: x = [8.6271861e-08 1.2940777e-07], Loss = 3.7795629934155375e-14\n",
      "Iteration 77: x = [6.9017489e-08 1.0352621e-07], Loss = 2.4189204377586884e-14\n",
      "Iteration 78: x = [5.521399e-08 8.282097e-08], Loss = 1.548109073389297e-14\n",
      "Iteration 79: x = [4.4171195e-08 6.6256774e-08], Loss = 9.907897696997004e-15\n",
      "Iteration 80: x = [3.5336956e-08 5.3005419e-08], Loss = 6.341054661603354e-15\n",
      "Iteration 81: x = [2.8269564e-08 4.2404334e-08], Loss = 4.0582750342481235e-15\n",
      "Iteration 82: x = [2.2615652e-08 3.3923467e-08], Loss = 2.5972956661649612e-15\n",
      "Iteration 83: x = [1.8092521e-08 2.7138773e-08], Loss = 1.6622693364598583e-15\n",
      "Iteration 84: x = [1.4474017e-08 2.1711019e-08], Loss = 1.0638523118068383e-15\n",
      "Iteration 85: x = [1.1579213e-08 1.7368816e-08], Loss = 6.808655176728591e-16\n",
      "Iteration 86: x = [9.2633705e-09 1.3895052e-08], Loss = 4.3575392919304747e-16\n",
      "Iteration 87: x = [7.4106965e-09 1.1116041e-08], Loss = 2.788825273890446e-16\n",
      "Iteration 88: x = [5.928557e-09 8.892833e-09], Loss = 1.7848479741195604e-16\n",
      "Iteration 89: x = [4.7428457e-09 7.1142665e-09], Loss = 1.142302809315637e-16\n",
      "Iteration 90: x = [3.7942764e-09 5.6914131e-09], Loss = 7.310737397284926e-17\n",
      "Iteration 91: x = [3.0354212e-09 4.5531303e-09], Loss = 4.678871696034336e-17\n",
      "Iteration 92: x = [2.4283371e-09 3.6425043e-09], Loss = 2.9944778589921956e-17\n",
      "Iteration 93: x = [1.9426696e-09 2.9140035e-09], Loss = 1.9164658099026705e-17\n",
      "Iteration 94: x = [1.5541357e-09 2.3312028e-09], Loss = 1.2265381183377091e-17\n",
      "Iteration 95: x = [1.2433086e-09 1.8649622e-09], Loss = 7.849843924274114e-18\n",
      "Iteration 96: x = [9.9464681e-10 1.4919698e-09], Loss = 5.023900061904596e-18\n",
      "Iteration 97: x = [7.9571744e-10 1.1935758e-09], Loss = 3.2152961223370027e-18\n",
      "Iteration 98: x = [6.3657396e-10 9.5486064e-10], Loss = 2.057789410762202e-18\n",
      "Iteration 99: x = [5.092592e-10 7.638885e-10], Loss = 1.3169851691210695e-18\n",
      "Iteration 100: x = [4.0740736e-10 6.1111083e-10], Loss = 8.428705744119335e-19\n",
      "\n",
      "Optimization Complete!\n",
      "Optimized x: [4.0740736e-10 6.1111083e-10]\n",
      "Final Loss: 5.394372027788135e-19\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# 目的関数 (例: x^2 + y^2 の最小化)\n",
    "def objective_function(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "# 最適化する変数の初期化\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)  # 初期値 [2.0, 3.0]\n",
    "\n",
    "# オプティマイザの選択 (SGD)\n",
    "optimizer = torch.optim.SGD([x], lr=0.1)  # 学習率 lr=0.1\n",
    "\n",
    "# 最適化ループ\n",
    "num_iterations = 100\n",
    "for iteration in range(num_iterations):\n",
    "    optimizer.zero_grad()  # 勾配のリセット\n",
    "\n",
    "    loss = objective_function(x)  # 目的関数の計算\n",
    "    loss.backward()  # 勾配の計算\n",
    "\n",
    "    optimizer.step()  # パラメータの更新\n",
    "\n",
    "    # 進捗を表示\n",
    "    print(f\"Iteration {iteration + 1}: x = {x.detach().numpy()}, Loss = {loss.item()}\")\n",
    "\n",
    "# 結果の表示\n",
    "print(\"\\nOptimization Complete!\")\n",
    "print(f\"Optimized x: {x.detach().numpy()}\")\n",
    "print(f\"Final Loss: {objective_function(x).item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
